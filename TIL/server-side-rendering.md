# server-side-rendering

## SEO

검색 엔진 최적화 (Search Engine Optimization)

1.  웹사이트에서 검색엔진으로 정보를 가져오는 방식이 검색 엔진마다 조금씩 다르다.
2.  정보를 가져온 뒤에 어떤 웹사이트를 상위에 보여줄 것인가를 결정하는 알고리즘이 조금씩 다르다.
    거기에 맞춰서 웹사이트를 만들어주고, 우리 웹사이트가 상위에 뜨도록 어떻게던 만들어주는 것을 SEO 라고 한다.

구글: 리액트 홈페이지를 링크 걸어놓은 웹사이트들이 많음 그 웹사이트들의 개수를 세서 구글에서 리액트를 검색했을 때 무엇을 띄워줄까를 결정한다.
다른 사이트들로 부터 오는 링크가 가장 많음
정확한 알고리즘은 공개하지 않음
돈과 직결되는 문제이기 때문에 악용할 수 있기 때문에 방향성은 공개하지만, 정확히 공개하지 않는다.
2 번 영역까지 프론트엔드가 신경쓸 수는 없다. 1 번에만 신경쓰면 된다.

User-agent: * -> 요쳥을 보낸 브라우저가 무엇인지, 네이버만 우리 웹사이트를 긁어갈 수 있게 하겠다 yeti 로 설정하면된다. 퍼블릭 폴더에(웹사이트의 루트 폴더에 다 복사가 된다.) 빌드하면 개발용 파일을 운영할 수 있는 파일로 바꿔준다. *로 세팅(모든 웹사이트가 긁어갈 수 있도록 설정)
Disallow: /version/  
robots.txt

meta tag 의 내용도 확인하고 있다.

meta tag 로 검색엔진에 정보를 쌓는다.
검색 엔진에 정보를 잘알려주려면, 메타 태그를 잘 써줘야 함.

메타 태그가 없다면, html 문서에 있는 태그를 긁어가서 정보를 쌓아놓음

어떻게 가져갈까?
검색엔진이 우리 웹사이트의 내용을 가져가려면 검색엔진도 요청을 보내야 된다.
검색엔진의 크롤러라고 한다.(포스트맨같은 건데, 자동화가 엄청나게 되어있다.)

### 포인트

robots.txt meta html
정보검색들도 우리 웹사이트에 요청을 보내서 정보를 받아가는 것이다.

https://boring-bell-7c476f.netlify.com/login 경로로 요쳥을 보냈을 때, 검색엔진은 로그인 기능이 없으니까. 처음 접속했을 때 뜨는 페이지들이 그 정보를 긁어갈 수 있으면 가장 좋은 것이다?

https://boring-bell-7c476f.netlify.com/ 로 요청을 보내면
렌더링 되어있던 root div 는 텅 비어있다.
우리의 사이트는 자바스크립트로 되어있음
포스트맨에서는 요청을 해서 응답을 받아서 그려주는 기능만이 있다. 스크립트를 실행시키지는 않는다.
root 안에 정보를 알 수 없다.
리액트로 만들어진 웹사이트를 요청을 보내면 정보를 제대로 받아갈 수 없는 문제가 생긴다.

구글같은 선도적인 검색엔진들이 자바스크립트를 실행시키는 경우가 있지만, 모든 경우에 다 알아먹는 것이 아니다. 리액트 라우터를 쓰면은 잘 못아랑먹은닫.

쇼핑몰의 각 상품들이 검색엔진에 걸려야 한다.
쇼핑몰 파란색 운동화 입력하면 파란색 운동화가 검색엔진에 걸려야 하는데 안됨.

서버사이드렌더링은 포스트맨같이 자바스크립트해석을 하지 못하는 클라이언트가 요청을 보내도 페이지에 있는 정보를 잘 보여주게끔 하기 위해 만들어진 기술이다.

https://reactjs.org/ get 요청보내면 정보를 줌 우리꺼는 텅빔

## 서버사이드 렌더링을 하려면 어떤 처리들이 필요할까?

일단 브라우저가

create-react-app 직접 서버사이드렌더링을 하려면 복잡.
직접 짜는 경우는 많지 않음
서버사이드렌더링을 미리 적용을 시켜놓은 것을 이용해서 구현하는 것이 대세임.

-> next.js

프로그램을 돌릴 수 있는 진짜 서버가 필요함(netlify 에서 뭔가를 할 순 없다.)

별도의 서버에서 이 프로그램을 띄워놔야 웹사이트를 운영할 수 있다. ?

파일들만 가지고 웹사이트를 할 수 있는데
어딘가에서 npm run dev npm start 를 해줘야 된다.??????? 뭔말이야

react-router 를 쓸 때 어느 경로로 들어와도 index.html 로 올 수 있도록 서버를 설정해줘야 한다.
화면을 보여주기 위해서는 어떤 경로로 요청이 들어오더라도, 항상 똑같은 index.html 을 브라우저에게 줘야 한다.

지금은 경로에 따라서 다 다른 html 을 보여줘야 한다.
서버사이드렌더링을 할 떄 라우팅 처리와 서버사이드렌더링을 안 할 때 라우트 처리가 다름

next.js 는 리액트 라우터에서 쓰는 방식과 epress 에서 쓰는 방식을 합친 무언가가 있어야 한다.
서버쪽과 브라우저쪽에서 잘 라우팅을 해줘야 한다.

익스프레스의 라우팅 기능(서버로 요청이 들어올 떄 서버로 어떤 경로에 요청이 들어오는지에 따라서 다른 응답을 줬었다. 실제로 어떤 경로로 들어왔는지에 따라서 다른 응답
그러나 여전히 리액트 앱처럼 동작을 해야 한다. push state 를 해줘서 빨리 빨리 해줘야 한다. 두 가지 다 필요)

next js 는 자체 라우터를 가지고 있다. 내장되어있는 라우터를 써야 한다.
css 라이프사이클 메소드등도 다 내장
next.js 가 내장되어ㅣㅇㅆ는 기능으 ㄹ활용하면 아주쉽게 할 수 있다.

- css
- head 관련 컴포넌트
- 라이프사이클을 통해서 받아와야 한다.
- 라우터

이런 규칙만 지키면 서버사이드렌더링이 되는 사이트를 쉽게 만들 수 있다.

express 에도 routing 기능이 들어있다

## Server-Side-Rendering 은 모든 부분에 다 필요한가? SSR

쓰는 이유? 검색엔진한테 정보를 주기 위해서 쓴다.

트렐로같이 나만 보는 웹사이틑는 검색엔진에 걸릴 필요가 없다.
검색엔진에 걸릴필요가 없는 개인화된 웹사이트인 경우, 서버사이드렌더링이 필요가 없다.
할 일 관리 앱은 개인화된 서비스
검색엔진에 걸려야 하는 쇼핑몰, 게시판 등 누구한테던 정보를 제공하는 웹사이트는 필수로 서버사이드렌더링을 써야 한다.

이 개념에 대해서 이해 할 필요가 있다.

할 일 관리 서비스의 홍보는 해야 함.
보통 리액트로 만든 개인화 된 부분은 별도의 도메인으로 제공하고
홍보를 위한 페이지는 정적으로 서버사이드렌더링을
리액트, 핵쏘? 정적 웹사이트를 만들어내는 도구들이 있다. 이러한 도구를 통해서 홈페이지를 따로 만들어줌
따로 관리해주는 식으로 요즘은 서비스를 많이 해 줌

내가 만드는 웹사이트가 개인화 된 건지, 아닌건지를 보고 서버사이드렌더링을 할건지 말건지 결정해야 한다.

사실 서버사이드 렌더링 하지 않고도, 검색엔진에 걸리게 할 수 있다.
Prerendering

우리의 화면을 비동기 통신으로 화면을 그려주고 있다고 하면
중간 브라우저에서 어떤 시점에 html 을 검색엔진에게 넘겨줄 것인가.
로딩 인디케이터가 돌고 있을 때 그 것을 검색엔진에 넘겨줄것인가.
데이터를 불러온 후에 검색엔진에게 넘겨줄 것인가.
어느 시점에 그려진 html 을 넘겨주는 것을 쉽게 결정할 수 없다.(많이 기다려야 하나? 시점을 결정하기 힘듦)
어느 시점에 검색엔진에 넘겨줄 것인가를 설정해줘야 한다.

prerendering 에도 어느 시점의 html 을 넘겨주면 되는지 설정해야주어야 한다.
